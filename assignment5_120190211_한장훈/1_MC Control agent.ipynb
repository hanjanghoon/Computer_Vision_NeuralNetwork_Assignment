{"nbformat":4,"nbformat_minor":0,"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python [default]","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"},"colab":{"name":"1_MC Control agent.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"w2qew_MHwOVr","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592381055052,"user_tz":-540,"elapsed":2949,"user":{"displayName":"jh a","photoUrl":"","userId":"12317339413270191329"}}},"source":["import numpy as np"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BeijC0RjwOVw","colab_type":"text"},"source":["# On-Policy Monte-Carlo Control"]},{"cell_type":"code","metadata":{"id":"ZULC9qIxwOVx","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592381055055,"user_tz":-540,"elapsed":2947,"user":{"displayName":"jh a","photoUrl":"","userId":"12317339413270191329"}}},"source":["class Env:\n","    def __init__(self):\n","        self.grid_width = 5\n","        self.grid_height = self.grid_width\n","        self.action_grid = [(-1, 0), (1, 0), (0, -1), (0, 1)]     # U, D, L, R\n","        self.gtriangle1 = [1, 2]\n","        self.gtriangle2 = [2, 1]\n","        self.goal = [2, 2]\n","        \n","    def step(self, state, action):\n","        x, y = state\n","        \n","        # get next state by action\n","        x+= action[0]\n","        y+= action[1]\n","        \n","        if x < 0 :\n","            x = 0\n","        elif x > (self.grid_width-1) :\n","            x = (self.grid_width-1)\n","\n","        if y < 0 :\n","            y = 0\n","        elif y > (self.grid_width-1) :\n","            y = (self.grid_width-1)\n","        \n","        next_state = [x, y]\n","        \n","        # reward \n","        if next_state == self.gtriangle1 or next_state == self.gtriangle2:\n","            reward = -1\n","            done = True\n","        elif next_state == self.goal:\n","            reward = 1\n","            done = True\n","        else:\n","            reward = 0\n","            done = False\n","        \n","        return next_state, reward, done\n","    \n","    def reset(self):\n","        return [0, 0]"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"X8KlwfOtwOV0","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592381055057,"user_tz":-540,"elapsed":2944,"user":{"displayName":"jh a","photoUrl":"","userId":"12317339413270191329"}}},"source":["class MC_agent:\n","    def __init__(self):\n","        self.action_grid = [(-1, 0), (1, 0), (0, -1), (0, 1)]\n","        self.action_text= ['U', 'D', 'L', 'R']\n","        self.grid_width = 5\n","        self.grid_height = self.grid_width\n","        self.value_table = np.zeros((self.grid_width, self.grid_height))\n","        self.e = .1\n","        self.learning_rate = .01\n","        self.discount_factor = .95\n","        self.memory=[]\n","    \n","    def get_action(self, state):\n","        # with prob.Îµ take random action\n","        if np.random.randn() <  self.e :\n","            idx = np.random.choice(len(self.action_grid),1)[0]\n","        else :\n","            next_values = np.array([])\n","            for s in self.next_states(state):\n","                next_values= np.append(next_values, self.value_table[tuple(s)])\n","            max_value = np.amax(next_values)\n","            tie_Qchecker = np.where(next_values==max_value)[0]\n","            \n","            # if tie max value, get random\n","            if len(tie_Qchecker) > 1:\n","                idx = np.random.choice(tie_Qchecker, 1)[0]\n","            else :\n","                idx = np.argmax(next_values)\n","        action = self.action_grid[idx]\n","        return action\n","    \n","    def next_states(self, state):\n","        x, y = state\n","        next_S = []\n","        for action in self.action_grid:\n","            x, y = state\n","            # calculate x_coordinate\n","            x+=action[0]\n","            if x < 0:\n","                x = 0\n","            elif x > 4:\n","                x = 4               \n","            # calculate x_coordinate\n","            y+=action[1]\n","            if y < 0:\n","                y = 0\n","            elif y > 4:\n","                y = 4\n","            next_S.append([x, y])        \n","        return next_S    \n","        \n","    # using First visit MC    \n","    def update(self):\n","        G_t = 0\n","        visit_states=[]\n","        for sample in reversed(self.memory):\n","            state = sample[0]\n","            reward = sample[1]\n","            if state not in visit_states:\n","                visit_states.append(state)\n","                G_t = reward + self.discount_factor*G_t\n","                V_t = self.value_table[tuple(state)]\n","                # update Value\n","                self.value_table[tuple(state)] = V_t + self.learning_rate*(G_t - V_t)\n","        \n","    def memorizer(self, state, reward, done):\n","        self.memory.append([state, reward, done])\n","        \n","    def save_actionseq(self, action_sequence, action):\n","        idx = self.action_grid.index(action)\n","        action_sequence.append(self.action_text[idx])"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"KPM94x8dwOV3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592381068146,"user_tz":-540,"elapsed":16022,"user":{"displayName":"jh a","photoUrl":"","userId":"12317339413270191329"}},"outputId":"1c647b46-8221-42d0-88e2-a05719cceee4"},"source":["if __name__ == \"__main__\":\n","    env = Env()\n","    agent = MC_agent()\n","    total_episode = 10000\n","    sr=0\n","    \n","    for episode in range(total_episode):\n","        action_sequence=[]\n","        total_reward = 0\n","        state = env.reset()\n","        action = agent.get_action(state)\n","        done = False\n","        walk = 0\n","        \n","        while True:\n","            next_state, reward, done = env.step(state, action)\n","            agent.memorizer(state, reward, done)\n","            agent.save_actionseq(action_sequence, action)\n","            walk += 1\n","            \n","            # next state and action \n","            state = next_state\n","            action = agent.get_action(state)\n","            total_reward+=reward\n","            \n","            if done:\n","                if episode % 100 == 0 :\n","                    print('finished at', state)\n","                    print('episode :{}, The number of step:{}\\n The sequence of action is:\\\n","                          {}\\nThe total reward is: {}\\n'.format(episode, walk, action_sequence, total_reward))\n","                if state == env.goal:\n","                    sr+=1\n","                agent.update()\n","                agent.memory.clear()\n","                break\n","                \n","print('The accuracy :', sr/total_episode*100, '%')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["finished at [2, 1]\n","episode :0, The number of step:3\n"," The sequence of action is:                          ['D', 'R', 'D']\n","The total reward is: -1\n","\n","finished at [1, 2]\n","episode :100, The number of step:3\n"," The sequence of action is:                          ['R', 'R', 'D']\n","The total reward is: -1\n","\n","finished at [1, 2]\n","episode :200, The number of step:44\n"," The sequence of action is:                          ['R', 'R', 'U', 'R', 'R', 'R', 'D', 'D', 'R', 'L', 'D', 'U', 'D', 'U', 'D', 'U', 'D', 'U', 'D', 'U', 'D', 'D', 'U', 'R', 'L', 'U', 'D', 'U', 'D', 'L', 'L', 'R', 'D', 'U', 'R', 'L', 'R', 'U', 'D', 'L', 'R', 'U', 'U', 'L']\n","The total reward is: -1\n","\n","finished at [2, 2]\n","episode :300, The number of step:27\n"," The sequence of action is:                          ['R', 'R', 'R', 'R', 'D', 'D', 'U', 'D', 'U', 'U', 'L', 'R', 'L', 'U', 'D', 'R', 'U', 'D', 'D', 'L', 'U', 'D', 'R', 'L', 'D', 'L', 'U']\n","The total reward is: 1\n","\n","finished at [2, 1]\n","episode :400, The number of step:3\n"," The sequence of action is:                          ['D', 'D', 'R']\n","The total reward is: -1\n","\n","finished at [1, 2]\n","episode :500, The number of step:5\n"," The sequence of action is:                          ['R', 'R', 'R', 'D', 'L']\n","The total reward is: -1\n","\n","finished at [2, 2]\n","episode :600, The number of step:16\n"," The sequence of action is:                          ['R', 'R', 'R', 'R', 'R', 'D', 'D', 'D', 'R', 'L', 'L', 'L', 'R', 'L', 'R', 'U']\n","The total reward is: 1\n","\n","finished at [2, 2]\n","episode :700, The number of step:36\n"," The sequence of action is:                          ['U', 'R', 'U', 'R', 'R', 'L', 'R', 'U', 'U', 'D', 'R', 'D', 'R', 'L', 'R', 'L', 'R', 'L', 'D', 'R', 'D', 'U', 'R', 'L', 'U', 'D', 'R', 'D', 'U', 'L', 'U', 'D', 'R', 'L', 'U', 'L']\n","The total reward is: 1\n","\n","finished at [2, 2]\n","episode :800, The number of step:19\n"," The sequence of action is:                          ['R', 'R', 'R', 'R', 'D', 'R', 'D', 'L', 'R', 'L', 'D', 'U', 'D', 'R', 'U', 'L', 'U', 'D', 'L']\n","The total reward is: 1\n","\n","finished at [2, 1]\n","episode :900, The number of step:4\n"," The sequence of action is:                          ['L', 'D', 'R', 'D']\n","The total reward is: -1\n","\n","finished at [2, 1]\n","episode :1000, The number of step:7\n"," The sequence of action is:                          ['D', 'U', 'R', 'R', 'L', 'D', 'D']\n","The total reward is: -1\n","\n","finished at [2, 1]\n","episode :1100, The number of step:19\n"," The sequence of action is:                          ['U', 'L', 'R', 'R', 'U', 'R', 'R', 'R', 'U', 'U', 'L', 'R', 'D', 'L', 'D', 'D', 'L', 'L', 'U']\n","The total reward is: -1\n","\n","finished at [2, 2]\n","episode :1200, The number of step:51\n"," The sequence of action is:                          ['L', 'U', 'U', 'U', 'L', 'U', 'U', 'U', 'U', 'L', 'U', 'U', 'U', 'L', 'U', 'D', 'D', 'D', 'R', 'R', 'R', 'L', 'R', 'L', 'R', 'L', 'R', 'L', 'R', 'L', 'R', 'U', 'R', 'L', 'D', 'R', 'U', 'R', 'U', 'D', 'R', 'U', 'D', 'L', 'D', 'R', 'L', 'L', 'R', 'L', 'U']\n","The total reward is: 1\n","\n","finished at [2, 2]\n","episode :1300, The number of step:42\n"," The sequence of action is:                          ['R', 'R', 'R', 'L', 'R', 'R', 'U', 'U', 'D', 'D', 'D', 'L', 'U', 'D', 'D', 'R', 'R', 'U', 'U', 'D', 'L', 'L', 'R', 'D', 'U', 'L', 'R', 'L', 'L', 'D', 'L', 'U', 'R', 'D', 'D', 'U', 'R', 'R', 'L', 'R', 'L', 'U']\n","The total reward is: 1\n","\n","finished at [2, 2]\n","episode :1400, The number of step:22\n"," The sequence of action is:                          ['R', 'R', 'R', 'D', 'R', 'L', 'D', 'D', 'L', 'R', 'L', 'L', 'D', 'R', 'R', 'U', 'U', 'D', 'R', 'L', 'L', 'U']\n","The total reward is: 1\n","\n","finished at [1, 2]\n","episode :1500, The number of step:8\n"," The sequence of action is:                          ['U', 'R', 'R', 'R', 'D', 'U', 'D', 'L']\n","The total reward is: -1\n","\n","finished at [2, 2]\n","episode :1600, The number of step:9\n"," The sequence of action is:                          ['D', 'L', 'D', 'D', 'R', 'R', 'D', 'U', 'U']\n","The total reward is: 1\n","\n","finished at [2, 2]\n","episode :1700, The number of step:25\n"," The sequence of action is:                          ['R', 'R', 'R', 'R', 'L', 'R', 'R', 'L', 'R', 'U', 'D', 'U', 'U', 'D', 'D', 'L', 'D', 'L', 'D', 'U', 'R', 'L', 'D', 'U', 'U']\n","The total reward is: 1\n","\n","finished at [2, 2]\n","episode :1800, The number of step:29\n"," The sequence of action is:                          ['R', 'R', 'R', 'D', 'U', 'R', 'U', 'U', 'D', 'D', 'L', 'D', 'L', 'R', 'L', 'R', 'U', 'D', 'L', 'D', 'D', 'U', 'R', 'L', 'R', 'L', 'R', 'U', 'L']\n","The total reward is: 1\n","\n","finished at [2, 2]\n","episode :1900, The number of step:32\n"," The sequence of action is:                          ['R', 'R', 'U', 'R', 'R', 'R', 'D', 'R', 'L', 'D', 'U', 'U', 'R', 'D', 'D', 'L', 'D', 'U', 'D', 'D', 'R', 'L', 'D', 'U', 'U', 'D', 'L', 'D', 'U', 'R', 'L', 'U']\n","The total reward is: 1\n","\n","finished at [2, 1]\n","episode :2000, The number of step:4\n"," The sequence of action is:                          ['U', 'R', 'D', 'D']\n","The total reward is: -1\n","\n","finished at [2, 2]\n","episode :2100, The number of step:73\n"," The sequence of action is:                          ['R', 'D', 'L', 'L', 'U', 'R', 'R', 'R', 'R', 'D', 'D', 'L', 'R', 'L', 'R', 'L', 'D', 'U', 'D', 'L', 'R', 'R', 'U', 'L', 'D', 'L', 'R', 'L', 'L', 'L', 'R', 'L', 'R', 'R', 'R', 'L', 'R', 'R', 'L', 'L', 'R', 'L', 'R', 'L', 'R', 'L', 'L', 'L', 'R', 'R', 'R', 'D', 'U', 'L', 'R', 'U', 'U', 'D', 'D', 'L', 'R', 'D', 'U', 'L', 'R', 'L', 'R', 'L', 'R', 'L', 'D', 'U', 'U']\n","The total reward is: 1\n","\n","finished at [1, 2]\n","episode :2200, The number of step:6\n"," The sequence of action is:                          ['R', 'U', 'D', 'U', 'D', 'R']\n","The total reward is: -1\n","\n","finished at [2, 1]\n","episode :2300, The number of step:3\n"," The sequence of action is:                          ['D', 'R', 'D']\n","The total reward is: -1\n","\n","finished at [2, 1]\n","episode :2400, The number of step:43\n"," The sequence of action is:                          ['R', 'R', 'L', 'R', 'R', 'R', 'D', 'D', 'D', 'L', 'D', 'R', 'L', 'L', 'U', 'R', 'U', 'D', 'L', 'R', 'L', 'R', 'L', 'R', 'L', 'L', 'D', 'R', 'D', 'U', 'R', 'D', 'U', 'L', 'R', 'L', 'L', 'D', 'R', 'D', 'U', 'L', 'U']\n","The total reward is: -1\n","\n","finished at [1, 2]\n","episode :2500, The number of step:6\n"," The sequence of action is:                          ['R', 'U', 'R', 'L', 'R', 'D']\n","The total reward is: -1\n","\n","finished at [1, 2]\n","episode :2600, The number of step:3\n"," The sequence of action is:                          ['R', 'R', 'D']\n","The total reward is: -1\n","\n","finished at [2, 2]\n","episode :2700, The number of step:23\n"," The sequence of action is:                          ['R', 'L', 'R', 'R', 'R', 'R', 'R', 'D', 'D', 'L', 'D', 'D', 'U', 'U', 'D', 'L', 'R', 'D', 'R', 'L', 'U', 'L', 'U']\n","The total reward is: 1\n","\n","finished at [2, 2]\n","episode :2800, The number of step:13\n"," The sequence of action is:                          ['U', 'U', 'L', 'U', 'D', 'D', 'L', 'D', 'U', 'D', 'R', 'R', 'U']\n","The total reward is: 1\n","\n","finished at [2, 1]\n","episode :2900, The number of step:4\n"," The sequence of action is:                          ['L', 'R', 'D', 'D']\n","The total reward is: -1\n","\n","finished at [2, 2]\n","episode :3000, The number of step:13\n"," The sequence of action is:                          ['D', 'R', 'U', 'R', 'U', 'R', 'R', 'L', 'R', 'D', 'D', 'L', 'L']\n","The total reward is: 1\n","\n","finished at [2, 2]\n","episode :3100, The number of step:29\n"," The sequence of action is:                          ['L', 'L', 'L', 'U', 'U', 'L', 'U', 'R', 'R', 'L', 'L', 'U', 'U', 'U', 'U', 'U', 'U', 'L', 'D', 'L', 'D', 'D', 'D', 'R', 'R', 'U', 'R', 'U', 'L']\n","The total reward is: 1\n","\n","finished at [2, 2]\n","episode :3200, The number of step:47\n"," The sequence of action is:                          ['U', 'D', 'D', 'L', 'D', 'D', 'U', 'R', 'D', 'R', 'R', 'U', 'L', 'R', 'L', 'R', 'R', 'R', 'U', 'R', 'D', 'L', 'U', 'D', 'R', 'D', 'L', 'U', 'L', 'D', 'L', 'R', 'R', 'U', 'D', 'U', 'L', 'R', 'L', 'R', 'R', 'R', 'L', 'L', 'R', 'L', 'U']\n","The total reward is: 1\n","\n","finished at [2, 2]\n","episode :3300, The number of step:15\n"," The sequence of action is:                          ['U', 'D', 'U', 'L', 'D', 'L', 'D', 'D', 'D', 'R', 'U', 'R', 'D', 'U', 'U']\n","The total reward is: 1\n","\n","finished at [2, 1]\n","episode :3400, The number of step:17\n"," The sequence of action is:                          ['R', 'L', 'D', 'U', 'D', 'D', 'D', 'R', 'L', 'R', 'R', 'R', 'D', 'L', 'U', 'L', 'U']\n","The total reward is: -1\n","\n","finished at [2, 2]\n","episode :3500, The number of step:20\n"," The sequence of action is:                          ['D', 'L', 'D', 'D', 'L', 'U', 'D', 'D', 'R', 'L', 'R', 'R', 'U', 'D', 'D', 'L', 'D', 'R', 'U', 'U']\n","The total reward is: 1\n","\n","finished at [1, 2]\n","episode :3600, The number of step:15\n"," The sequence of action is:                          ['U', 'L', 'U', 'D', 'D', 'D', 'R', 'L', 'U', 'U', 'D', 'U', 'L', 'R', 'R']\n","The total reward is: -1\n","\n","finished at [1, 2]\n","episode :3700, The number of step:4\n"," The sequence of action is:                          ['U', 'D', 'R', 'R']\n","The total reward is: -1\n","\n","finished at [2, 1]\n","episode :3800, The number of step:25\n"," The sequence of action is:                          ['L', 'L', 'U', 'D', 'D', 'L', 'D', 'L', 'D', 'L', 'U', 'L', 'L', 'D', 'R', 'R', 'U', 'L', 'R', 'D', 'U', 'D', 'L', 'U', 'U']\n","The total reward is: -1\n","\n","finished at [1, 2]\n","episode :3900, The number of step:32\n"," The sequence of action is:                          ['L', 'U', 'U', 'D', 'D', 'D', 'L', 'D', 'R', 'R', 'U', 'D', 'U', 'D', 'U', 'D', 'L', 'D', 'R', 'D', 'U', 'R', 'R', 'U', 'R', 'R', 'R', 'L', 'R', 'U', 'L', 'L']\n","The total reward is: -1\n","\n","finished at [2, 2]\n","episode :4000, The number of step:11\n"," The sequence of action is:                          ['R', 'L', 'D', 'D', 'D', 'D', 'R', 'R', 'D', 'U', 'U']\n","The total reward is: 1\n","\n","finished at [2, 2]\n","episode :4100, The number of step:39\n"," The sequence of action is:                          ['U', 'R', 'R', 'R', 'R', 'L', 'U', 'U', 'R', 'D', 'D', 'L', 'D', 'D', 'L', 'R', 'U', 'L', 'R', 'R', 'R', 'D', 'D', 'L', 'U', 'L', 'R', 'L', 'R', 'L', 'R', 'L', 'D', 'R', 'U', 'U', 'D', 'U', 'L']\n","The total reward is: 1\n","\n","finished at [2, 1]\n","episode :4200, The number of step:6\n"," The sequence of action is:                          ['D', 'D', 'L', 'U', 'D', 'R']\n","The total reward is: -1\n","\n","finished at [2, 2]\n","episode :4300, The number of step:34\n"," The sequence of action is:                          ['D', 'D', 'D', 'L', 'L', 'D', 'R', 'D', 'R', 'U', 'R', 'L', 'R', 'L', 'R', 'L', 'R', 'R', 'D', 'U', 'D', 'R', 'L', 'R', 'U', 'L', 'L', 'R', 'L', 'R', 'L', 'L', 'R', 'U']\n","The total reward is: 1\n","\n","finished at [2, 1]\n","episode :4400, The number of step:5\n"," The sequence of action is:                          ['R', 'L', 'R', 'D', 'D']\n","The total reward is: -1\n","\n","finished at [1, 2]\n","episode :4500, The number of step:4\n"," The sequence of action is:                          ['R', 'U', 'D', 'R']\n","The total reward is: -1\n","\n","finished at [2, 2]\n","episode :4600, The number of step:14\n"," The sequence of action is:                          ['R', 'R', 'R', 'R', 'U', 'R', 'D', 'L', 'D', 'D', 'U', 'D', 'L', 'U']\n","The total reward is: 1\n","\n","finished at [2, 2]\n","episode :4700, The number of step:15\n"," The sequence of action is:                          ['L', 'R', 'R', 'U', 'R', 'R', 'D', 'U', 'L', 'R', 'U', 'D', 'D', 'L', 'L']\n","The total reward is: 1\n","\n","finished at [2, 2]\n","episode :4800, The number of step:58\n"," The sequence of action is:                          ['R', 'R', 'R', 'D', 'D', 'U', 'R', 'U', 'L', 'R', 'D', 'D', 'R', 'R', 'R', 'U', 'D', 'L', 'D', 'D', 'R', 'L', 'D', 'D', 'U', 'L', 'R', 'D', 'R', 'U', 'D', 'D', 'U', 'D', 'D', 'U', 'L', 'R', 'L', 'L', 'R', 'D', 'U', 'L', 'R', 'U', 'D', 'L', 'R', 'L', 'R', 'D', 'D', 'U', 'L', 'R', 'U', 'L']\n","The total reward is: 1\n","\n","finished at [2, 2]\n","episode :4900, The number of step:17\n"," The sequence of action is:                          ['R', 'L', 'U', 'R', 'U', 'R', 'R', 'U', 'D', 'D', 'D', 'D', 'U', 'L', 'R', 'L', 'U']\n","The total reward is: 1\n","\n","finished at [2, 1]\n","episode :5000, The number of step:5\n"," The sequence of action is:                          ['U', 'L', 'D', 'D', 'R']\n","The total reward is: -1\n","\n","finished at [2, 2]\n","episode :5100, The number of step:16\n"," The sequence of action is:                          ['D', 'L', 'D', 'L', 'D', 'D', 'R', 'R', 'R', 'U', 'L', 'R', 'L', 'D', 'U', 'U']\n","The total reward is: 1\n","\n","finished at [2, 2]\n","episode :5200, The number of step:13\n"," The sequence of action is:                          ['D', 'R', 'L', 'D', 'D', 'D', 'U', 'D', 'L', 'R', 'R', 'U', 'U']\n","The total reward is: 1\n","\n","finished at [1, 2]\n","episode :5300, The number of step:50\n"," The sequence of action is:                          ['D', 'D', 'D', 'R', 'R', 'R', 'L', 'D', 'U', 'D', 'L', 'R', 'D', 'R', 'U', 'L', 'R', 'R', 'L', 'L', 'R', 'U', 'D', 'U', 'D', 'R', 'R', 'L', 'L', 'R', 'L', 'L', 'D', 'L', 'D', 'R', 'R', 'R', 'U', 'L', 'R', 'D', 'U', 'L', 'L', 'R', 'R', 'U', 'U', 'L']\n","The total reward is: -1\n","\n","finished at [2, 2]\n","episode :5400, The number of step:28\n"," The sequence of action is:                          ['U', 'R', 'R', 'U', 'U', 'U', 'U', 'R', 'R', 'R', 'D', 'L', 'D', 'D', 'L', 'R', 'L', 'R', 'L', 'R', 'D', 'U', 'L', 'R', 'L', 'R', 'L', 'U']\n","The total reward is: 1\n","\n","finished at [1, 2]\n","episode :5500, The number of step:8\n"," The sequence of action is:                          ['U', 'L', 'R', 'R', 'L', 'R', 'U', 'D']\n","The total reward is: -1\n","\n","finished at [1, 2]\n","episode :5600, The number of step:3\n"," The sequence of action is:                          ['R', 'R', 'D']\n","The total reward is: -1\n","\n","finished at [2, 1]\n","episode :5700, The number of step:3\n"," The sequence of action is:                          ['D', 'D', 'R']\n","The total reward is: -1\n","\n","finished at [2, 1]\n","episode :5800, The number of step:10\n"," The sequence of action is:                          ['U', 'L', 'D', 'D', 'D', 'L', 'U', 'D', 'U', 'R']\n","The total reward is: -1\n","\n","finished at [2, 2]\n","episode :5900, The number of step:49\n"," The sequence of action is:                          ['D', 'D', 'D', 'D', 'U', 'D', 'R', 'R', 'D', 'U', 'R', 'L', 'R', 'L', 'R', 'L', 'D', 'D', 'R', 'U', 'L', 'R', 'D', 'D', 'U', 'L', 'D', 'U', 'L', 'R', 'L', 'R', 'L', 'R', 'R', 'R', 'L', 'L', 'D', 'R', 'R', 'U', 'U', 'D', 'L', 'L', 'R', 'L', 'U']\n","The total reward is: 1\n","\n","finished at [2, 2]\n","episode :6000, The number of step:72\n"," The sequence of action is:                          ['D', 'D', 'D', 'D', 'D', 'L', 'D', 'R', 'R', 'U', 'L', 'D', 'R', 'R', 'U', 'D', 'R', 'L', 'U', 'L', 'R', 'U', 'D', 'L', 'R', 'D', 'U', 'L', 'R', 'L', 'R', 'L', 'R', 'L', 'R', 'L', 'R', 'L', 'R', 'L', 'R', 'L', 'R', 'D', 'U', 'D', 'U', 'L', 'R', 'R', 'L', 'L', 'R', 'D', 'U', 'L', 'R', 'R', 'U', 'D', 'L', 'L', 'R', 'D', 'D', 'R', 'L', 'U', 'L', 'R', 'U', 'L']\n","The total reward is: 1\n","\n","finished at [2, 2]\n","episode :6100, The number of step:13\n"," The sequence of action is:                          ['D', 'D', 'L', 'D', 'L', 'U', 'D', 'L', 'D', 'R', 'R', 'U', 'U']\n","The total reward is: 1\n","\n","finished at [2, 1]\n","episode :6200, The number of step:5\n"," The sequence of action is:                          ['D', 'D', 'U', 'R', 'D']\n","The total reward is: -1\n","\n","finished at [1, 2]\n","episode :6300, The number of step:4\n"," The sequence of action is:                          ['U', 'R', 'R', 'D']\n","The total reward is: -1\n","\n","finished at [1, 2]\n","episode :6400, The number of step:11\n"," The sequence of action is:                          ['L', 'U', 'D', 'D', 'U', 'U', 'L', 'R', 'U', 'R', 'D']\n","The total reward is: -1\n","\n","finished at [1, 2]\n","episode :6500, The number of step:8\n"," The sequence of action is:                          ['U', 'D', 'D', 'U', 'D', 'U', 'R', 'R']\n","The total reward is: -1\n","\n","finished at [2, 1]\n","episode :6600, The number of step:5\n"," The sequence of action is:                          ['R', 'D', 'L', 'D', 'R']\n","The total reward is: -1\n","\n","finished at [2, 2]\n","episode :6700, The number of step:50\n"," The sequence of action is:                          ['D', 'U', 'L', 'L', 'L', 'U', 'U', 'D', 'D', 'D', 'D', 'R', 'D', 'U', 'D', 'D', 'D', 'R', 'U', 'R', 'D', 'L', 'D', 'U', 'R', 'R', 'D', 'U', 'L', 'L', 'D', 'U', 'R', 'L', 'R', 'R', 'U', 'D', 'D', 'U', 'R', 'R', 'L', 'D', 'U', 'L', 'D', 'D', 'U', 'U']\n","The total reward is: 1\n","\n","finished at [2, 1]\n","episode :6800, The number of step:5\n"," The sequence of action is:                          ['U', 'L', 'D', 'D', 'R']\n","The total reward is: -1\n","\n","finished at [1, 2]\n","episode :6900, The number of step:26\n"," The sequence of action is:                          ['D', 'L', 'D', 'D', 'D', 'U', 'R', 'R', 'R', 'D', 'D', 'U', 'L', 'L', 'R', 'R', 'D', 'U', 'R', 'U', 'R', 'U', 'L', 'U', 'D', 'L']\n","The total reward is: -1\n","\n","finished at [2, 2]\n","episode :7000, The number of step:34\n"," The sequence of action is:                          ['U', 'D', 'U', 'L', 'R', 'L', 'D', 'R', 'U', 'R', 'R', 'R', 'R', 'R', 'D', 'D', 'L', 'D', 'L', 'D', 'U', 'R', 'L', 'R', 'L', 'R', 'L', 'D', 'R', 'U', 'L', 'R', 'L', 'U']\n","The total reward is: 1\n","\n","finished at [2, 2]\n","episode :7100, The number of step:13\n"," The sequence of action is:                          ['D', 'D', 'D', 'D', 'U', 'D', 'L', 'R', 'R', 'U', 'R', 'L', 'U']\n","The total reward is: 1\n","\n","finished at [2, 1]\n","episode :7200, The number of step:6\n"," The sequence of action is:                          ['D', 'L', 'R', 'L', 'R', 'D']\n","The total reward is: -1\n","\n","finished at [2, 2]\n","episode :7300, The number of step:14\n"," The sequence of action is:                          ['D', 'L', 'D', 'D', 'L', 'L', 'D', 'L', 'D', 'L', 'R', 'U', 'R', 'U']\n","The total reward is: 1\n","\n","finished at [2, 1]\n","episode :7400, The number of step:9\n"," The sequence of action is:                          ['R', 'L', 'D', 'R', 'L', 'D', 'D', 'R', 'U']\n","The total reward is: -1\n","\n","finished at [2, 1]\n","episode :7500, The number of step:7\n"," The sequence of action is:                          ['U', 'L', 'D', 'D', 'U', 'D', 'R']\n","The total reward is: -1\n","\n","finished at [2, 2]\n","episode :7600, The number of step:14\n"," The sequence of action is:                          ['D', 'D', 'D', 'U', 'D', 'D', 'R', 'R', 'U', 'R', 'L', 'L', 'R', 'U']\n","The total reward is: 1\n","\n","finished at [2, 1]\n","episode :7700, The number of step:5\n"," The sequence of action is:                          ['U', 'D', 'L', 'D', 'R']\n","The total reward is: -1\n","\n","finished at [2, 1]\n","episode :7800, The number of step:4\n"," The sequence of action is:                          ['L', 'D', 'D', 'R']\n","The total reward is: -1\n","\n","finished at [1, 2]\n","episode :7900, The number of step:3\n"," The sequence of action is:                          ['R', 'D', 'R']\n","The total reward is: -1\n","\n","finished at [2, 2]\n","episode :8000, The number of step:62\n"," The sequence of action is:                          ['R', 'R', 'R', 'L', 'R', 'U', 'U', 'D', 'D', 'R', 'R', 'L', 'D', 'U', 'U', 'U', 'R', 'D', 'D', 'L', 'D', 'D', 'U', 'U', 'D', 'U', 'D', 'D', 'U', 'U', 'D', 'L', 'R', 'L', 'D', 'R', 'L', 'U', 'R', 'L', 'D', 'U', 'R', 'L', 'R', 'D', 'U', 'L', 'R', 'D', 'D', 'U', 'L', 'R', 'L', 'R', 'R', 'R', 'R', 'L', 'L', 'U']\n","The total reward is: 1\n","\n","finished at [1, 2]\n","episode :8100, The number of step:6\n"," The sequence of action is:                          ['L', 'U', 'L', 'R', 'D', 'R']\n","The total reward is: -1\n","\n","finished at [2, 2]\n","episode :8200, The number of step:23\n"," The sequence of action is:                          ['R', 'R', 'R', 'R', 'D', 'D', 'D', 'U', 'D', 'U', 'L', 'R', 'U', 'D', 'L', 'R', 'R', 'U', 'L', 'D', 'D', 'U', 'L']\n","The total reward is: 1\n","\n","finished at [2, 1]\n","episode :8300, The number of step:3\n"," The sequence of action is:                          ['R', 'D', 'D']\n","The total reward is: -1\n","\n","finished at [2, 2]\n","episode :8400, The number of step:16\n"," The sequence of action is:                          ['R', 'R', 'R', 'R', 'R', 'U', 'R', 'D', 'U', 'D', 'R', 'D', 'L', 'R', 'L', 'L']\n","The total reward is: 1\n","\n","finished at [1, 2]\n","episode :8500, The number of step:7\n"," The sequence of action is:                          ['R', 'R', 'L', 'L', 'R', 'D', 'R']\n","The total reward is: -1\n","\n","finished at [2, 1]\n","episode :8600, The number of step:8\n"," The sequence of action is:                          ['D', 'D', 'L', 'D', 'D', 'R', 'U', 'U']\n","The total reward is: -1\n","\n","finished at [2, 2]\n","episode :8700, The number of step:27\n"," The sequence of action is:                          ['R', 'R', 'R', 'R', 'D', 'D', 'L', 'R', 'R', 'D', 'U', 'D', 'L', 'U', 'U', 'R', 'D', 'L', 'U', 'D', 'R', 'L', 'D', 'U', 'R', 'L', 'L']\n","The total reward is: 1\n","\n","finished at [1, 2]\n","episode :8800, The number of step:29\n"," The sequence of action is:                          ['L', 'U', 'R', 'R', 'U', 'L', 'L', 'U', 'R', 'R', 'R', 'R', 'R', 'D', 'U', 'R', 'L', 'U', 'U', 'R', 'D', 'D', 'U', 'D', 'L', 'R', 'L', 'U', 'L']\n","The total reward is: -1\n","\n","finished at [2, 2]\n","episode :8900, The number of step:24\n"," The sequence of action is:                          ['U', 'U', 'U', 'U', 'U', 'U', 'D', 'D', 'D', 'D', 'R', 'U', 'D', 'L', 'L', 'U', 'D', 'R', 'R', 'D', 'U', 'R', 'U', 'L']\n","The total reward is: 1\n","\n","finished at [2, 1]\n","episode :9000, The number of step:5\n"," The sequence of action is:                          ['U', 'U', 'D', 'D', 'R']\n","The total reward is: -1\n","\n","finished at [2, 2]\n","episode :9100, The number of step:15\n"," The sequence of action is:                          ['R', 'L', 'R', 'R', 'R', 'R', 'D', 'D', 'D', 'R', 'L', 'U', 'D', 'U', 'L']\n","The total reward is: 1\n","\n","finished at [2, 2]\n","episode :9200, The number of step:14\n"," The sequence of action is:                          ['D', 'D', 'D', 'D', 'R', 'R', 'L', 'R', 'U', 'R', 'R', 'L', 'L', 'U']\n","The total reward is: 1\n","\n","finished at [1, 2]\n","episode :9300, The number of step:14\n"," The sequence of action is:                          ['R', 'R', 'L', 'R', 'U', 'R', 'R', 'D', 'R', 'U', 'U', 'D', 'L', 'L']\n","The total reward is: -1\n","\n","finished at [2, 2]\n","episode :9400, The number of step:34\n"," The sequence of action is:                          ['U', 'R', 'L', 'R', 'R', 'R', 'R', 'U', 'D', 'D', 'L', 'D', 'L', 'L', 'R', 'R', 'U', 'D', 'U', 'D', 'D', 'U', 'U', 'D', 'R', 'L', 'U', 'D', 'U', 'U', 'R', 'D', 'L', 'L']\n","The total reward is: 1\n","\n","finished at [2, 2]\n","episode :9500, The number of step:31\n"," The sequence of action is:                          ['U', 'U', 'D', 'D', 'D', 'D', 'R', 'R', 'L', 'R', 'R', 'U', 'U', 'D', 'U', 'D', 'U', 'R', 'R', 'L', 'D', 'U', 'D', 'D', 'U', 'U', 'D', 'R', 'U', 'L', 'L']\n","The total reward is: 1\n","\n","finished at [2, 2]\n","episode :9600, The number of step:18\n"," The sequence of action is:                          ['D', 'D', 'U', 'L', 'D', 'D', 'D', 'R', 'R', 'D', 'R', 'U', 'U', 'U', 'D', 'D', 'U', 'L']\n","The total reward is: 1\n","\n","finished at [2, 1]\n","episode :9700, The number of step:4\n"," The sequence of action is:                          ['L', 'D', 'D', 'R']\n","The total reward is: -1\n","\n","finished at [2, 1]\n","episode :9800, The number of step:7\n"," The sequence of action is:                          ['D', 'D', 'D', 'U', 'D', 'U', 'R']\n","The total reward is: -1\n","\n","finished at [2, 2]\n","episode :9900, The number of step:13\n"," The sequence of action is:                          ['R', 'L', 'L', 'R', 'R', 'R', 'R', 'D', 'L', 'D', 'D', 'U', 'L']\n","The total reward is: 1\n","\n","The accuracy : 52.6 %\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MunXaF9mwOV7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":107},"executionInfo":{"status":"ok","timestamp":1592381068148,"user_tz":-540,"elapsed":16014,"user":{"displayName":"jh a","photoUrl":"","userId":"12317339413270191329"}},"outputId":"6b1eadf1-1da6-4ffb-d2ce-2a075fc87c66"},"source":["agent.value_table"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[-0.01778219,  0.00173448,  0.07027257,  0.31807991,  0.45327218],\n","       [-0.03679505, -0.53769129,  0.        ,  0.27727623,  0.50177026],\n","       [ 0.11331332,  0.        ,  0.        ,  0.68630107,  0.61163694],\n","       [ 0.37011571,  0.34679193,  0.59913546,  0.65439169,  0.61544138],\n","       [ 0.42668923,  0.47771908,  0.5621389 ,  0.57223967,  0.59911758]])"]},"metadata":{"tags":[]},"execution_count":5}]}]}